{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab113c6",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c648dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scapy.all import *\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f62b87",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d56159b",
   "metadata": {},
   "source": [
    "Accessing the dataset \"USTC 2016\" that I will use for implementing a real-time IDS for network attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad0f3007",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = \"datasets/USTC-TFC2016-master\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e258a97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_conversations(pcap_file):\n",
    "    conversations = {}  # Dictionary to store conversations\n",
    "\n",
    "    for packet in rdpcap(pcap_file):\n",
    "        \n",
    "        if packet.haslayer(IP):\n",
    "            src_ip = packet[IP].src\n",
    "            dst_ip = packet[IP].dst\n",
    "\n",
    "            if packet.haslayer(TCP):\n",
    "                src_port = packet[TCP].sport\n",
    "                dst_port = packet[TCP].dport\n",
    "                key = (src_ip, dst_ip, src_port, dst_port)\n",
    "            elif packet.haslayer(UDP):\n",
    "                src_port = packet[UDP].sport\n",
    "                dst_port = packet[UDP].dport\n",
    "                key = (src_ip, dst_ip, src_port, dst_port)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if key not in conversations:\n",
    "                conversations[key] = []\n",
    "            conversations[key].append(packet)\n",
    "    return conversations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395af764",
   "metadata": {},
   "source": [
    "Exctracting conversations based on 4 dimentional key - ip src, ip dst, src port, dst port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ac15201",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcap_file = f\"{WORK_DIR}/Benign/FTP.pcap\"\n",
    "conversations = extract_conversations(pcap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e7b2775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202034"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conversations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638444fb",
   "metadata": {},
   "source": [
    "We have extracted from this single FTP pcap 202034 conversations (all benign).\n",
    "For each conversation we want to take the first two frames, but first let's look at a conversation that contains more than a single frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7684deb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[('1.1.153.239', '1.2.53.138', 17225, 51825)][0][IP][Raw].load.hex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a67e75",
   "metadata": {},
   "source": [
    "This is the IP stack that i will convert to an image in the dataframe.\n",
    "Let's populate a df with the data that will be analyzed later in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "06b7fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data_to_df(conversations, n=2, save_images=False):\n",
    "    \n",
    "    def save_data_as_bmp(index, row):\n",
    "        predifined_header = f\"424d1e06000000000000360000002800000018000000{hex(height)}0000000100180000000000e8050000000000000000000000000000000000004500\"\n",
    "\n",
    "        with open(f\"{index}.bmp\", \"wb\") as bmp_file:\n",
    "          # Write the byte string to the file in binary mode\n",
    "          bmp_file.write(bytes.fromhex(predifined_header + row.padded_image))\n",
    "    \n",
    "    width = 24\n",
    "    height = 21*n\n",
    "    df = pd.DataFrame(columns=[\"dataset\", \"pcap\", \"padded_image\"])\n",
    "\n",
    "    for index, (key, conv) in enumerate(conversations.items()):\n",
    "        textual_data = \"\"\n",
    "        \n",
    "        for i in range(n):\n",
    "            try:\n",
    "                if len(conv) > i:\n",
    "                    textual_data += conv[i][IP].load.hex()\n",
    "            except:\n",
    "                print(key)\n",
    "                return conv\n",
    "        # Pad data\n",
    "        textual_data = textual_data + \"0\"*(height*width*3*2-len(textual_data))\n",
    "        \n",
    "        tmp_df = pd.DataFrame({\n",
    "            \"dataset\": [\"USTC16\"],\n",
    "            \"pcap\": [\"FTP\"],\n",
    "            \"padded_image\": [textual_data]\n",
    "        })\n",
    "        df = pd.concat([df, tmp_df])\n",
    "        print(f\"{index}/{len(conversations)}\", end=\"\\r\")\n",
    "        \n",
    "    if save_images:\n",
    "        for index, row in df.iterrows():\n",
    "            save_data_as_bmp(index, row)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009dd5f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_converted = convert_data_to_df(conversations, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d30ce5",
   "metadata": {},
   "source": [
    "Now that we transformed a pcap conversations to images we can implement the process the research \"Detection of Malicious Network Flows with Low Preprocessing Overhead\" proposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
